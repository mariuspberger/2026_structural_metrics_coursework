{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting line_profiler\n",
      "  Downloading line_profiler-5.0.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\n",
      "Downloading line_profiler-5.0.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: line_profiler\n",
      "Successfully installed line_profiler-5.0.0\n"
     ]
    }
   ],
   "source": [
    "# install line profiler\n",
    "!pip install line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of model_zucher_exante failed: Traceback (most recent call last):\n",
      "  File \"/home/marius/data/0_Programme/anaconda3/lib/python3.13/site-packages/IPython/extensions/autoreload.py\", line 325, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marius/data/0_Programme/anaconda3/lib/python3.13/site-packages/IPython/extensions/autoreload.py\", line 580, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/marius/data/0_Programme/anaconda3/lib/python3.13/importlib/__init__.py\", line 129, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 866, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1023, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1161, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1091, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"/home/marius/Data/0_Programme/Github_desktop_repos/2026_structural_metrics_coursework/lab4/model_zucher_exante.py\", line 111\n",
      "    remove_first_row_index=idx-np.append(0,idx[:-1])\n",
      "IndentationError: unexpected indent\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# magics: ensures that any changes to the modules loaded below will be re-loaded automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "\n",
    "# load general packages\n",
    "import numpy as np\n",
    "\n",
    "# load modules related to this exercise\n",
    "from model_zucher_exante import zurcher\n",
    "from Solve_NFXP_exante import solve_NFXP\n",
    "import estimate_NFXP_exante as estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Look at ReadMe.txt to get an overview of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Invistigate how the code works, that is ensure you understand:\n",
    "<il type =\"a\">\n",
    "<li> zurcher.init</li>\n",
    "<li> zurcher.setup</li>\n",
    "<li> zurcher.create_grid</li>\n",
    "<li> zucher.state_transition </li>\n",
    "<li> zucher.bellman </li>\n",
    "\n",
    "You can see how they are called below\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Fill in the missing stuff in the function zucher.bellman and run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model grid:\n",
      " [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "Transition probabilities conditional on not replacing:\n",
      " [[0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.15]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.35]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]]\n",
      "Transition probabilities conditional on replacing:\n",
      " [[0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "Bellman one run:\n",
      " [0.47272635 0.47027066 0.46781497 0.46535928 0.46290359 0.4604479\n",
      " 0.45799221 0.45553652 0.45308083 0.45074793 0.44866059 0.44706439]\n"
     ]
    }
   ],
   "source": [
    "do_settings = {\n",
    "    'RC': 0.5,\n",
    "    'n': 12,\n",
    "    'p':[0.65,0.2,0.1]   \n",
    "}\n",
    "model = zurcher(**do_settings)\n",
    "\n",
    "print('Model grid:\\n',model.grid)\n",
    "print('Transition probabilities conditional on not replacing:\\n',model.P1)\n",
    "print('Transition probabilities conditional on replacing:\\n',model.P2)\n",
    "ev,pk, dev = model.bellman(np.zeros((model.n)),output=3)\n",
    "print('Bellman one run:\\n',ev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "### 4. Solve the model. In order to solve the model, you should understand:\n",
    "<li> solve_NFXP.init</li>\n",
    "<li> solve_NFXP.setup</li>\n",
    "<li> solve_NFXP.poly </li>\n",
    "<li> solve_NFXP.sa </li>\n",
    "<li> solve_NFXP.nk </li>\n",
    "</il>\n",
    "You can see how they are called below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin contraction iterations (for the 1 time)\n",
      "Iteration 1, tol     0.4273, tol(j)/tol(j-1)          1\n",
      "Iteration 2, tol     0.4272, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 3, tol     0.4272, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 4, tol     0.4272, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 5, tol     0.4271, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 6, tol     0.4271, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 7, tol      0.427, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 8, tol      0.427, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 9, tol     0.4269, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 10, tol     0.4269, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 11, tol     0.4269, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 12, tol     0.4268, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 13, tol     0.4268, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 14, tol     0.4267, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 15, tol     0.4267, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 16, tol     0.4266, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 17, tol     0.4266, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 18, tol     0.4266, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 19, tol     0.4265, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 20, tol     0.4265, tol(j)/tol(j-1)     0.9999\n",
      "Maximum number of iterations reached, tolerance: 0.4265\n",
      "Elapsed time 0.0010 seconds\n",
      "Begin Newton-Kantorovich iterations (for the 1 time)\n",
      "Iteration 1, tol  0.0001525, tol(j)/tol(j-1)          1\n",
      "Iteration 2, tol  4.177e-08, tol(j)/tol(j-1)   0.000274\n",
      "Iteration 3, tol      1e-11, tol(j)/tol(j-1)  0.0002395\n",
      "N-K converged after 3 iterations, tolerance: 1e-11\n",
      "Elapsed time 0.0305 seconds\n",
      "Convergence achieved!\n",
      "Elapsed time: 0.0319 (seconds)\n"
     ]
    }
   ],
   "source": [
    "algorithm = 'poly'\n",
    "do_settings_solver = {\n",
    "    'sa_min': 10,\n",
    "    'sa_max': 20,  \n",
    "    'printfxp': 2\n",
    "}\n",
    "\n",
    "solver = solve_NFXP(**do_settings_solver)\n",
    "model = zurcher()\n",
    "\n",
    "if algorithm == 'sa':\n",
    "    ev = solver.sa(model.bellman)\n",
    "if algorithm == 'poly':\n",
    "    ev = solver.poly(model.bellman)\n",
    "else:\n",
    "    print('Algorithm must be \"sa\" or \"poly\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Now we have to estimate the model. In order to estimate the model, you should understand:\n",
    "<il type =\"a\">\n",
    "<li> zurcher.read_busdata </li>\n",
    "<li> estimate_NFXP.estimate  </li>\n",
    "<li> estimate_NFXP.ll  </li>\n",
    "</il>\n",
    "\n",
    "You can see how they are called below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Fill in the missing stuff in the function estimate_NFXP.ll, and estimate the model to check that your results are correct\n",
    "##### Check for missing sign somewhere, c should be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structual estimation using busdata from Rust(1987)\n",
      "Beta        = 0.9999\n",
      "n           = 175\n",
      "Sample size = 8156\n",
      " \n",
      "\n",
      "Parameters     Estimates    s.e. \n",
      "RC             4.7610     0.6378 \n",
      "c              -1.3001     0.1068 \n",
      " \n",
      "p(1)           0.1069     0.0034  \n",
      "p(2)           0.5154     0.0055  \n",
      "p(3)           0.3621     0.0053  \n",
      "p(4)           0.0143     0.0013  \n",
      "\n",
      "Log-likelihood -8660.55\n",
      "runtime (seconds) 0.5429\n",
      "The model converged: True\n"
     ]
    }
   ],
   "source": [
    "# Set up the model\n",
    "model = zurcher()\n",
    "\n",
    "# Set-up solver\n",
    "solver = solve_NFXP()\n",
    "\n",
    "# Read the data\n",
    "data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "samplesize = data.shape[0]\n",
    "\n",
    "# Estimate the model\n",
    "import time\n",
    "t0 = time.time()\n",
    "theta0 = [0,0]\n",
    "\n",
    "# args for nfxp estimate\n",
    "nfxp_model, optim_res, pnames, theta_hat, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "t1 = time.time()\n",
    "time = t1-t0\n",
    "\n",
    "# Print the result\n",
    "print(f'Structual estimation using busdata from Rust(1987)')\n",
    "print(f'Beta        = {model.beta:.4f}')\n",
    "print(f'n           = {model.n}')\n",
    "print(f'Sample size = {samplesize}\\n \\n')\n",
    "\n",
    "print(f'Parameters     Estimates    s.e. ') \n",
    "print(f'{pnames[0]}             {theta_hat[0]:.4f}     {np.sqrt(Avar[0,0]):.4f} ')\n",
    "print(f'{pnames[1]}              {theta_hat[1]:.4f}     {np.sqrt(Avar[1,1]):.4f} \\n ')\n",
    "print(f'{pnames[2]}(1)           {theta_hat[2]:.4f}     {np.sqrt(Avar[2,2]):.4f}  ')\n",
    "print(f'{pnames[2]}(2)           {theta_hat[3]:.4f}     {np.sqrt(Avar[3,3]):.4f}  ')\n",
    "print(f'{pnames[2]}(3)           {theta_hat[4]:.4f}     {np.sqrt(Avar[4,4]):.4f}  ')\n",
    "print(f'{pnames[2]}(4)           {theta_hat[5]:.4f}     {np.sqrt(Avar[5,5]):.4f}  \\n')\n",
    "\n",
    "\n",
    "print(f'Log-likelihood {-optim_res.fun*samplesize:.2f}') \n",
    "print(f'runtime (seconds) {time:.4f}')\n",
    "print(f'The model converged: {converged}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Try using line_profiler in python. This gives you a lot of information about the performance of your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.485592 s\n",
      "File: /home/marius/Data/0_Programme/Github_desktop_repos/2026_structural_metrics_coursework/lab4/estimate_NFXP_exante.py\n",
      "Function: ll at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           #  NFXP class for structural estimation of discrete choice models.\n",
      "     2                                           \n",
      "     3        70    8187294.0 116961.3      1.7  import numpy as np\n",
      "\n",
      "Total time: 0.514935 s\n",
      "File: /home/marius/Data/0_Programme/Github_desktop_repos/2026_structural_metrics_coursework/lab4/estimate_NFXP_exante.py\n",
      "Function: estimate at line 11\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    11                                           \n",
      "    12                                           def estimate(model,solver,data,theta0=[0,0],twostep=0): # theta0 = initial value of structural parameter\n",
      "    13         1      13759.0  13759.0      0.0      global ev\n",
      "    14                                               ev = np.zeros(1) \n",
      "    15         1      20953.0  20953.0      0.0      \n",
      "    16                                               samplesize = data.shape[0]\n",
      "    17         1    1128586.0 1.13e+06      0.2      # STEP 1: Find p \n",
      "    18         1     218677.0 218677.0      0.0      tabulate = data.dx1.value_counts()\n",
      "    19                                               p = [tabulate[i]/sum(tabulate) for i in range(tabulate.size-1)]\n",
      "    20                                           \n",
      "    21         1       2934.0   2934.0      0.0      # STEP 2: Estimate structual parameters\n",
      "    22                                               model.p = p # Use first step estimates as starting values for p\n",
      "    23                                               \n",
      "    24         1       2375.0   2375.0      0.0      # Estimate RC and C\n",
      "    25                                               pnames = ['RC','c']\n",
      "    26         1  339717448.0  3.4e+08     66.0      \n",
      "    27                                               res = optimize.minimize(\n",
      "    28                                                   ll,\n",
      "    29         1      24864.0  24864.0      0.0          theta0,\n",
      "    30                                                   args = (model, solver, data, pnames), \n",
      "    31                                                   method = 'trust-ncg',\n",
      "    32         1       3283.0   3283.0      0.0          jac = grad, # to be computed\n",
      "    33         1       3841.0   3841.0      0.0          hess = hes, # to be computed\n",
      "    34         1       9079.0   9079.0      0.0          tol=1e-8\n",
      "    35         1  167181904.0 1.67e+08     32.5      )\n",
      "    36                                               \n",
      "    37         1      22979.0  22979.0      0.0      \n",
      "    38                                               model=updatepar(model,pnames,res.x)\n",
      "    39                                               \n",
      "    40         1       5168.0   5168.0      0.0      # Estimate RC, c and p\n",
      "    41                                               if twostep == 0:\n",
      "    42                                                   pnames = ['RC','c','p']\n",
      "    43         1    6520850.0 6.52e+06      1.3          theta0 = [model.RC, model.c] + model.p.tolist()\n",
      "    44         1      50008.0  50008.0      0.0          res = optimize.minimize(ll,theta0, args = (model,solver,data, pnames), method = 'trust-ncg',jac = grad, hess = hes, tol = 1e-8)\n",
      "    45                                           \n",
      "    46         1       5308.0   5308.0      0.0          model=updatepar(model,pnames,res.x)\n",
      "    47                                           \n",
      "    48         1       2864.0   2864.0      0.0      # Converged\n",
      "    49                                               converged   =   (res.status == 2 or res.status ==0)\n",
      "    50                                           \n",
      "    51                                               # Compute Variance-Covaiance matrix\n",
      "    52                                               h = hes(res.x, model, solver,data, pnames)\n",
      "    53                                               Avar = np.linalg.inv(h*samplesize)\n",
      "    54                                           \n",
      "    55                                               theta_hat = res.x\n",
      "    56                                               \n",
      "    57                                               return model, res, pnames, theta_hat, Avar, converged"
     ]
    }
   ],
   "source": [
    "%lprun -f estimate.ll  -f estimate.estimate estimate.estimate(model, solver,data,theta0=theta0, twostep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.0162548 s\n",
      "File: /home/marius/Data/0_Programme/Github_desktop_repos/2026_structural_metrics_coursework/lab4/Solve_NFXP_exante.py\n",
      "Function: solve_NFXP.poly at line 31\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    31                                               def poly(self,bellman, V0=np.zeros(1), beta= 0.0, output=1):\n",
      "    32                                           \n",
      "    33         1       6146.0   6146.0      0.0          t0poly = time.time()  # set the starting time\n",
      "    34                                           \n",
      "    35         6      15155.0   2525.8      0.1          for k in range(self.max_fxpiter):\n",
      "    36                                           \n",
      "    37                                                       # 1. CONTRACTION ITERATIONS (S-A)\n",
      "    38         5      10964.0   2192.8      0.1              if self.printfxp>0:\n",
      "    39                                                           print(f'Begin contraction iterations (for the {k+1} time)')\n",
      "    40         5    3522858.0 704571.6     21.7              V0,iter_sa= self.sa(bellman,V0,beta)\n",
      "    41                                           \n",
      "    42                                                       # 2. NEWTON-KANTOROVICH ITERATIONS\n",
      "    43         5      13130.0   2626.0      0.1              if self.printfxp>0:\n",
      "    44                                                           print(f'Begin Newton-Kantorovich iterations (for the {k+1} time)')\n",
      "    45         5   12631445.0 2.53e+06     77.7              V0,pk,dV, iter_nk = self.nk(bellman,V0)\n",
      "    46                                           \n",
      "    47                                           \n",
      "    48         5      22139.0   4427.8      0.1              t1poly = time.time()\n",
      "    49         5      14108.0   2821.6      0.1              if iter_nk.converged=='true':\n",
      "    50         5      12712.0   2542.4      0.1                  if self.printfxp>0:\n",
      "    51                                                               print(f'Convergence achieved!')\n",
      "    52                                                               print(f'Elapsed time: {(t1poly-t0poly):.4f} (seconds)')\n",
      "    53                                                               break \n",
      "    54                                                       else:\n",
      "    55                                                           if k >= self.max_fxpiter:\n",
      "    56                                                               print(f'No convergence! Maximum number of iterations exceeded without convergence!')\n",
      "    57                                                               break\n",
      "    58         1       2375.0   2375.0      0.0          V = V0\n",
      "    59         1       1886.0   1886.0      0.0          if output==1:            \n",
      "    60         1       1886.0   1886.0      0.0              return V\n",
      "    61                                                   if output==2:            \n",
      "    62                                                       return V, pk\n",
      "    63                                                   if output==3:            \n",
      "    64                                                       return V, pk, dV\n",
      "    65                                                   if output==5:            \n",
      "    66                                                       return V, pk, dV, iter_sa, iter_nk\n",
      "    67                                                   else:\n",
      "    68                                                       print('solve_NFXP.poly: output must be 1,2,3 or 5')\n",
      "\n",
      "Total time: 0.0121742 s\n",
      "File: /home/marius/Data/0_Programme/Github_desktop_repos/2026_structural_metrics_coursework/lab4/Solve_NFXP_exante.py\n",
      "Function: solve_NFXP.nk at line 107\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   107                                               def nk(self,bellman, V0):\n",
      "   108         5      94148.0  18829.6      0.8          class iteration: pass\n",
      "   109         5      19136.0   3827.2      0.2          t0 = time.time()\n",
      "   110         5      33663.0   6732.6      0.3          iteration.tol =  np.nan+np.zeros((self.pi_max))\n",
      "   111         5      21371.0   4274.2      0.2          iteration.rtol = np.nan+np.zeros((self.pi_max))\n",
      "   112         5      11874.0   2374.8      0.1          iteration.converged = 'false'\n",
      "   113                                           \n",
      "   114         5      14389.0   2877.8      0.1          m = V0.size\n",
      "   115                                           \n",
      "   116        12      40510.0   3375.8      0.3          for i in range(self.pi_max):\n",
      "   117                                           \n",
      "   118                                                       # Do N-K step\n",
      "   119        12    1802774.0 150231.2     14.8              V1, pk, dV = bellman(V0,output=3)\n",
      "   120        12     477025.0  39752.1      3.9              F = np.eye(m)-dV\n",
      "   121        12    8429367.0 702447.2     69.2              V = V0 - np.linalg.inv(F) @ (V0 - V1) \n",
      "   122                                                       \n",
      "   123                                                       # do additional SA iteration for stability and accurate measure of error bound\n",
      "   124        12     475767.0  39647.2      3.9              V0 = bellman(V,output=1)\n",
      "   125                                           \n",
      "   126                                                       # Tolerance\n",
      "   127        12     241235.0  20102.9      2.0              iteration.tol[i]=max(abs(V-V0))\n",
      "   128        12      49170.0   4097.5      0.4              iteration.rtol[i] = iteration.tol[i]/(iteration.tol[max(i-1,0)] + 1.0e-15)      \n",
      "   129                                           \n",
      "   130                                                       #Adjust \n",
      "   131        12     202406.0  16867.2      1.7              adj  = np.ceil(np.log10(abs(max(V0))))\n",
      "   132        12      37085.0   3090.4      0.3              ltol = self.pi_tol*10**adj  # Adjust final tolerance\n",
      "   133                                           \n",
      "   134        12      37435.0   3119.6      0.3              if iteration.tol[i] < ltol:\n",
      "   135                                                           #Convergence achieved\n",
      "   136         5      42952.0   8590.4      0.4                  iteration.message = \"N-K converged after {} iterations, tolerance: {:.4g}\".format(i+1,iteration.tol[i])\n",
      "   137         5      14737.0   2947.4      0.1                  iteration.converged = 'true'\n",
      "   138         5      11943.0   2388.6      0.1                  break\n",
      "   139                                                   \n",
      "   140         5      16273.0   3254.6      0.1          iteration.n = i+1\n",
      "   141         5      17250.0   3450.0      0.1          iteration.tol = iteration.tol[0:i+1]\n",
      "   142         5      13689.0   2737.8      0.1          iteration.rtol = iteration.rtol[0:i+1]\n",
      "   143         5      23677.0   4735.4      0.2          t1 = time.time()\n",
      "   144         5      12711.0   2542.2      0.1          iteration.time = t1-t0 \n",
      "   145                                           \n",
      "   146         5      22071.0   4414.2      0.2          self.print_output(iteration)\n",
      "   147                                           \n",
      "   148         5      11525.0   2305.0      0.1          return V, pk, dV, iteration"
     ]
    }
   ],
   "source": [
    "%lprun -f solve_NFXP.nk -f solve_NFXP.poly solve_NFXP.poly(solver,model.bellman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Now try changing the optimizer options, and turn the use of the non-numerical Hessian off . What happens?\n",
    "\n",
    "b) Now also try it with the analytical gradient off, what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Try estimate the model for different values of $\\beta$. \n",
    "\n",
    "(a) Why can we not estimate $\\beta$?\n",
    "\n",
    "(b) When estimating with different $\\beta$, do the changes in the estimates of c and/or RC make intuitively sense?\n",
    "\n",
    "(c) Can you think of some data/variation, which could allow us to identify $\\beta$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. We use the latest EV guess to start the solve-procedure even though we change $\\theta$ from one likelihood iteration to another. Why do you think we do that? \n",
    "(a) What if we started over with EV=0 each iteration? Try that and see what happens with the parameters and the numerical performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Try setting the maximum number of miles (odometer reading) to 900. Now the absorbing state is much higher. \n",
    "\n",
    "(a) If we adjust the number of grid points as well, so that we have a comparable model (multiply the number of grids by 2), do we get a better fit? \n",
    "\n",
    "(b) Try to lower the number of grid points to 175 again. How do the parameters change? Are the changes intuitive? \n",
    "\n",
    "(c) What if you change the max to 225 and half the number of grids (hint: what goes wrong?)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
